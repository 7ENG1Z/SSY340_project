{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from models import*\n",
    "from load_data import loaddata,loaddata_with_label_map\n",
    "from train_utils import TrainModel,validation,show_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '../WLASL_agument (final)'\n",
    "DATA_PATH = '/home/lizi/Desktop/WLASL_agument(combine)'\n",
    "\n",
    "\n",
    "X,Y ,label_map= loaddata(DATA_PATH)\n",
    "print(label_map)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_PATH = '../WLASL_agument (final)'\n",
    "DATA_PATH = '/home/lizi/Desktop/lizi'\n",
    "\n",
    "X_my,Y_my = loaddata_with_label_map(DATA_PATH,label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mytrain, X_myval, Y_mytrain, Y_myval = train_test_split(X_my, Y_my, random_state=21,test_size=0.2)\n",
    "#test dataloader\n",
    "mytrain = TensorDataset(torch.tensor(X_mytrain, dtype=torch.float), torch.tensor(Y_mytrain, dtype=torch.long))\n",
    "mytrain_loader = DataLoader(mytrain, batch_size=10, shuffle=True)\n",
    "#test dataloader\n",
    "myval = TensorDataset(torch.tensor(X_myval, dtype=torch.float), torch.tensor(Y_myval, dtype=torch.long))\n",
    "myval_loader = DataLoader(myval, batch_size=10, shuffle=True)\n",
    "\n",
    "optimizer1 = torch.optim.Adam(model_lstm.parameters(), lr=0.000001)\n",
    "\n",
    "num_epochs = 60\n",
    "\n",
    "fine_tuning = TrainModel(lstm_wlasl_model,device,criterion,optimizer1)\n",
    "tuned_lstm, train_losses_tune, train_accs_tune, val_losses_tune, val_accs_tune = fine_tuning.fit(num_epochs,mytrain_loader,myval_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_result(train_losses_tune, train_accs_tune, val_losses_tune, val_accs_tune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save({'model_state_dict': tuned_lstm.state_dict(),\n",
    "            'train_losses': train_losses_tune,\n",
    "            'train_accs': train_accs_tune,\n",
    "            'val_losses': val_losses_tune,\n",
    "            'val_accs': val_accs_tune,\n",
    "            }, \"./fine_tuned_lstm_model.ckpt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sign_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
